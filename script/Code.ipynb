{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [X] Look at the data. What's the distribution of the target, `price`, and features such as `longitude` and `latitude`? Remove outliers.\n",
    "- [X] After you remove outliers, what is the mean price in your subset of the data?\n",
    "- [X] Choose a feature, and plot its relationship with the target.\n",
    "- [X] Use scikit-learn for linear regression with one feature. You can follow the [5-step process from Jake VanderPlas](https://jakevdp.github.io/PythonDataScienceHandbook/05.02-introducing-scikit-learn.html#Basics-of-the-API).\n",
    "- [X] Define a function to make new predictions and explain the model coefficient.\n",
    "- [X] Organize and comment your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "from functools import *\n",
    "from pyrthon import *\n",
    "from pyrsistent import *\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning, module='numpy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "appstate = {}\n",
    "appstate_history = v()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "print(appstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def comp(*functions):\n",
    "    \"\"\"comp: compose functions\"\"\"\n",
    "    return reduce(lambda f, g: lambda x: f(g(x)), functions, lambda x: x)\n",
    "\n",
    "def Map(func, iterable):\n",
    "    return list(map(func, iterable))\n",
    "\n",
    "def DictMerge(a, b):\n",
    "    return {**a, **b}\n",
    "\n",
    "def ChainDictMerge(a):\n",
    "    return reduce(lambda x, y: DictMerge(x, y), a)\n",
    "\n",
    "def rest(x):\n",
    "    return x[1:]\n",
    "\n",
    "def first(x):\n",
    "    return x[0]\n",
    "    \n",
    "def last(x):\n",
    "    return x[-1]\n",
    "\n",
    "def butlast(x):\n",
    "    return x[:-1]\n",
    "\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "def is_empty(x):\n",
    "    return len(x)==0\n",
    "\n",
    "def not_empty(x):\n",
    "    return converse(is_empty)(x)\n",
    "\n",
    "def converse(fn):\n",
    "    return lambda *args, **kwargs: not fn(*args, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions which do neither\n",
    "def WriteProfileReport(df, title=''):\n",
    "    profile = df.profile_report(title=title)\n",
    "    profile.to_file(output_file=\"output__{}.html\".format(title))\n",
    "    return profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other functions which work within the context of an appstate\n",
    "\n",
    "def GetZMatrix(df):\n",
    "    scaler = StandardScaler()\n",
    "    Z = pd.DataFrame(scaler.fit_transform(df.values), columns=df.columns)\n",
    "    return Z\n",
    "\n",
    "def ApplyDF(df, *args, **kwargs):\n",
    "    fn     = first(args)\n",
    "    args   = rest(args)\n",
    "    result = fn(df, *args, **kwargs)\n",
    "    return fn(df, *args, **kwargs)\n",
    "\n",
    "def FilterDF(df):\n",
    "    return (df[(df['price'] >= np.percentile(df['price'], 0.5)) & \n",
    "        (df['price'] <= np.percentile(df['price'], 99.5)) & \n",
    "        (df['latitude'] >= np.percentile(df['latitude'], 0.05)) & \n",
    "        (df['latitude'] < np.percentile(df['latitude'], 99.95)) &\n",
    "        (df['longitude'] >= np.percentile(df['longitude'], 0.05)) & \n",
    "        (df['longitude'] <= np.percentile(df['longitude'], 99.95))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other people's\n",
    "def regression_3d(df, x, y, z, **kwargs):\n",
    "    \"\"\"\n",
    "    Visualize linear regression in 3D: 2 features + 1 target\n",
    "    \n",
    "    df : Pandas DataFrame\n",
    "    x : string, feature 1 column in df\n",
    "    y : string, feature 2 column in df\n",
    "    z : string, target column in df\n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot data\n",
    "    fig = px.scatter_3d(df, x, y, z, **kwargs)\n",
    "    \n",
    "    # Fit Linear Regression\n",
    "    features = [x, y]\n",
    "    target = z\n",
    "    model = LinearRegression()\n",
    "    model.fit(df[features], df[target])    \n",
    "    \n",
    "    # Define grid of four points in the feature space\n",
    "    xmin, xmax = df[x].min(), df[x].max()\n",
    "    ymin, ymax = df[y].min(), df[y].max()\n",
    "    coords = [[xmin, ymin], \n",
    "              [xmin, ymax], \n",
    "              [xmax, ymin], \n",
    "              [xmax, ymax]]\n",
    "    \n",
    "    # Make predictions for the grid\n",
    "    Z = model.predict(coords).reshape((2,2), order='F')\n",
    "    \n",
    "    # Plot predictions as a 3D surface (plane)\n",
    "    fig.add_trace(go.Surface(x=[xmin,xmax], y=[ymin,ymax], z=Z))\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "def regression_residuals(df, feature, target, m, b):\n",
    "    \"\"\"\n",
    "    Visualize linear regression, with residual errors,\n",
    "    in 2D: 1 feature + 1 target.\n",
    "    \n",
    "    Use the m & b parameters to \"fit the model\" manually.\n",
    "    \n",
    "    df : Pandas DataFrame\n",
    "    feature : string, feature column in df\n",
    "    target : string, target column in df\n",
    "    m : numeric, slope for linear equation\n",
    "    b : numeric, intercept for linear requation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot data\n",
    "    df.plot.scatter(feature, target)\n",
    "    \n",
    "    # Make predictions\n",
    "    x = df[feature]\n",
    "    y = df[target]\n",
    "    y_pred = m*x + b\n",
    "    \n",
    "    # Plot predictions\n",
    "    plt.plot(x, y_pred)\n",
    "    \n",
    "    # Plot residual errors\n",
    "    for x, y1, y2 in zip(x, y, y_pred):\n",
    "        plt.plot((x, x), (y1, y2), color='grey')\n",
    "    \n",
    "    # Print regression metrics\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    print('Mean Absolute Error:', mae)\n",
    "    print('R^2:', r2)\n",
    "\n",
    "\n",
    "def regression_squared_errors(df, feature, target, m, b):\n",
    "    \"\"\"\n",
    "    Visualize linear regression, with squared errors,\n",
    "    in 2D: 1 feature + 1 target.\n",
    "    \n",
    "    Use the m & b parameters to \"fit the model\" manually.\n",
    "    \n",
    "    df : Pandas DataFrame\n",
    "    feature : string, feature column in df\n",
    "    target : string, target column in df\n",
    "    m : numeric, slope for linear equation\n",
    "    b : numeric, intercept for linear requation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Plot data\n",
    "    fig = plt.figure(figsize=(7,7))\n",
    "    ax = plt.axes()\n",
    "    df.plot.scatter(feature, target, ax=ax)\n",
    "    \n",
    "    # Make predictions\n",
    "    x = df[feature]\n",
    "    y = df[target]\n",
    "    y_pred = m*x + b\n",
    "    \n",
    "    # Plot predictions\n",
    "    ax.plot(x, y_pred)\n",
    "    \n",
    "    # Plot squared errors\n",
    "    xmin, xmax = ax.get_xlim()\n",
    "    ymin, ymax = ax.get_ylim()\n",
    "    scale = (xmax-xmin)/(ymax-ymin)\n",
    "    for x, y1, y2 in zip(x, y, y_pred):\n",
    "        bottom_left = (x, min(y1, y2))\n",
    "        height = abs(y1 - y2)\n",
    "        width = height * scale\n",
    "        ax.add_patch(Rectangle(xy=bottom_left, width=width, height=height, alpha=0.1))\n",
    "    \n",
    "    # Print regression metrics\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y, y_pred)\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    print('Mean Squared Error:', mse)\n",
    "    print('Root Mean Squared Error:', rmse)\n",
    "    print('Mean Absolute Error:', mae)\n",
    "    print('R^2:', r2)\n",
    "    \n",
    "# Credit: Jake VanderPlas, Python Data Science Handbook, Chapter 5.3\n",
    "# https://jakevdp.github.io/PythonDataScienceHandbook/05.03-hyperparameters-and-model-validation.html#Validation-curves-in-Scikit-Learn\n",
    "def PolynomialRegression(degree=2, **kwargs):\n",
    "    return make_pipeline(PolynomialFeatures(degree), \n",
    "                         LinearRegression(**kwargs))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
